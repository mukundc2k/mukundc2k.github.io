---
title:          "unveiLing: What makes Linguistics Olympiad puzzles tricky for LLMs?"
date:           2025-01-01 00:01:00 +0800
selected:       false
pub:            "NAACL submission"
pub_date:       "2025"

abstract: >-
  Large language models (LLMs) have demonstrated potential in reasoning tasks, but their performance on linguistics puzzles remains consistently poor. These puzzles, often derived from Linguistics Olympiad contests, provide a minimal contamination environment to assess LLMs' linguistic reasoning abilities across low-resource languages. In this work, we analyze 629 problems across 41 low-resource languages by labeling each with fine-grained linguistic and meta-linguistic features. Our analysis reveals that LLMs struggle with puzzles involving high morphological complexity and unequal representation of linguistic phenomena while handling syntactic complexity relatively well. We also find that most models tend to perform better on puzzles involving linguistic features present in English. These findings can offer insights into the challenges LLMs face in multilingual and sparse data settings and suggest improvements for future dataset and benchmark design in the domain.
cover:          /assets/images/covers/figure5.png
authors:
  - Mukund Choudhary*#
  - KV Aditya Srivatsa*#
  - Daria Kotova
  - Dang Khoa Dang Dinh
  - Ikhlasul Akmal Hanif
  - Antara Raaghavi Bhattacharya
  - Ekaterina Kochmar
  - Monojit Choudhury
links:
  OpenReview: https://openreview.net/forum?id=TvbouEnmSE
---
